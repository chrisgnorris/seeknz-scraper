{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seek NZ Scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Create a file with Jupyter and try and scrape Seek.co.nz\n",
    "###### Used https://www.youtube.com/watch?v=eN_3d4JrL_w as a base\n",
    "###### https://github.com/chrisgnorris/seeknz-scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from datetime import datetime\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_url(position, location):\n",
    "    \"\"\"Generate a url from position and location\"\"\"\n",
    "    template = 'https://www.seek.co.nz/{}-jobs/in-All-{}'\n",
    "    url = template.format(position, location)\n",
    "    return url\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = get_url('data-scientist','New-Zealand')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract raw html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cards = soup.find_all('article')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(cards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "section = soup.find('div', {'class':'_3MPUOLE'})\n",
    "x = 0\n",
    "for div in section.select('div[data-search-sol-meta]'):\n",
    "    x = x + 1\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jobs = soup.find_all('div[data-search-sol-meta]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Try to get Proxy via VPN working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Currently not working - obviously depends on the VPN provider and can be sticked. You can always just turn the VPN on\n",
    "#Or you use the proxy - even some free ones https://pypi.org/project/free-proxy/\n",
    "#This isn't required!!!\n",
    "\n",
    "# https://dev.to/thughes24/how-to-turn-your-vpn-into-a-proxy-using-python-28ag\n",
    "proxy = {\n",
    "    'http': \"test@gmail.com:password123@nz-akl.prod.surfshark.com\",\n",
    "    'https': \"test@gmail.com:password123@nz-akl.prod.surfshark.com\"\n",
    "}\n",
    "response2 = requests.get('https://google.com',proxies=proxy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "response2.reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use shadow socks from Surfshark\n",
    "# https://stackoverflow.com/questions/56934030/how-do-i-use-nordvpn-servers-as-python-requests-proxies/65441742#65441742"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prototype the model with a single record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "card = cards[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "atag = card.h1.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "job_title = atag.string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "job_url = 'https://www.seek.co.nz' + atag.get('href')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "company = card.find('span',{\"_3FrNV7v _3PZrylH E6m4BZb\"}).a.text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "card.find('span',{\"_3FrNV7v _3PZrylH E6m4BZb\"}).text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "location = card.find('div',{'class':'xxz8a1h'}).a.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "salary = card.find('span',{'class':'lwHBT6d'}).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "card.find_all('span',{'class':{'Eadjc1o' : 'location'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jobcategory = card.find(attrs={\"data-automation\": \"jobClassification\"}).text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prototype the model with a single record V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "card = cards[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "job_title = card.find(attrs={\"data-automation\": \"jobTitle\"}).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "job_url = 'https://www.seek.co.nz' + card.find(attrs={\"data-automation\": \"jobTitle\"}).get('href')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    company = card.find(attrs={\"data-automation\": \"jobCompany\"}).text\n",
    "except AttributeError:\n",
    "    company = ''\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "location = card.find(attrs={\"data-automation\": \"jobLocation\"}).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    job_salary = card.find(attrs={\"data-automation\": \"jobSalary\"}).text\n",
    "except AttributeError:\n",
    "    job_salary = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "job_category = card.find(attrs={\"data-automation\": \"jobClassification\"}).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "job_subcategory = card.find(attrs={\"data-automation\": \"jobSubClassification\"}).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "job_short_description = card.find(attrs={\"data-automation\": \"jobShortDescription\"}).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    job_listing_date = card.find(attrs={\"data-automation\": \"jobListingDate\"}).text\n",
    "except AttributeError:\n",
    "    job_listing_date = 'Featured'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "date_mined = datetime.today().strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "job_id = card.get('data-job-id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bullet_points = ''\n",
    "x = 0\n",
    "for li in card.select('li'):\n",
    "    if x == 0:\n",
    "        bullet_points = bullet_points + li.text\n",
    "        x = 1\n",
    "    else:\n",
    "        bullet_points = bullet_points + ' - ' + li.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generalise the model with a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_record(card):\n",
    "    \"\"\"Extract job data from a single record\"\"\"\n",
    "    card = cards[0]\n",
    "    job_title = card.find(attrs={\"data-automation\": \"jobTitle\"}).text\n",
    "    job_url = 'https://www.seek.co.nz' + card.find(attrs={\"data-automation\": \"jobTitle\"}).get('href')\n",
    "    company = card.find(attrs={\"data-automation\": \"jobCompany\"}).text\n",
    "    location = card.find(attrs={\"data-automation\": \"jobLocation\"}).text\n",
    "    try:\n",
    "        job_salary = card.find(attrs={\"data-automation\": \"jobSalary\"}).text\n",
    "    except AttributeError:\n",
    "        job_salary = ''\n",
    "    job_category = card.find(attrs={\"data-automation\": \"jobClassification\"}).text\n",
    "    job_subcategory = card.find(attrs={\"data-automation\": \"jobSubClassification\"}).text\n",
    "    job_short_description = card.find(attrs={\"data-automation\": \"jobShortDescription\"}).text\n",
    "    try:\n",
    "        job_listing_date = card.find(attrs={\"data-automation\": \"jobListingDate\"}).text\n",
    "    except AttributeError:\n",
    "        job_listing_date = 'Featured'\n",
    "    date_mined = datetime.today().strftime('%Y-%m-%d')\n",
    "    job_id = card.get('data-job-id')\n",
    "    bullet_points = ''\n",
    "    x = 0\n",
    "    for li in card.select('li'):\n",
    "        if x == 0:\n",
    "            bullet_points = bullet_points + li.text\n",
    "            x = 1\n",
    "        else:\n",
    "            bullet_points = bullet_points + ' - ' + li.text\n",
    "            \n",
    "    record = (job_id,job_title,company,location,jobshortdescription,bullet_points,job_salary,jobcategory,jobsubcategory,job_url)\n",
    "    \n",
    "    return record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "records = []\n",
    "\n",
    "for card in cards:\n",
    "    record = get_record(card)\n",
    "    records.append(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(records[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the next page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "while True:\n",
    "    try:\n",
    "        url = 'https://www.seek.co.nz' + soup.find(attrs={\"data-automation\": \"page-next\"}).get('href')\n",
    "    except AttributeError:\n",
    "        break\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    cards = soup.find_all('article')\n",
    "    \n",
    "    for card in cards:\n",
    "    record = get_record(card)\n",
    "    records.append(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(len(records))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving File to Excel and referencing as a dataframe to ignore previously mined files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Opening existing file as DB\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv('results.csv')  \n",
    "except FileNotFoundError:\n",
    "    print('No existing file found')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/60675117/returning-a-string-from-loc-query\n",
    "#https://stackoverflow.com/questions/56260348/selecting-single-value-in-a-pandas-dataframe\n",
    "lookup = df.loc[df['ID'] == '1111', 'ID'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if lookup.size > 0:\n",
    "    print('Found')\n",
    "else:\n",
    "    print('Not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Put together\n",
    "def lookup_ID(jobid):\n",
    "    \"\"\"Feed URL for it to look up, will return found or not found\"\"\"\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv('results.csv')  \n",
    "        lookup = df.loc[df['ID'] == jobid, 'ID'].values\n",
    "        \n",
    "        if lookup.size > 0:\n",
    "            searchResult = 'Found'\n",
    "         \n",
    "        else:\n",
    "            searchResult = 'Not found'\n",
    "        \n",
    "        return searchResult\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        searchResult = 'No existing csv file found'\n",
    "        return searchResult\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lookup_ID(51160410)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mine hidden salary data from Seek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/37465172/how-to-use-beautifulsoup-to-scrape-a-webpage-url\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_url_salary(jobid_salary):\n",
    "    \"\"\"Generate a url to get salary info from seek job id\"\"\"\n",
    "    template = 'https://qdjrmx4vb1.execute-api.ap-southeast-2.amazonaws.com/chickennuggets?jobId={}'\n",
    "    url = template.format(jobid_salary)\n",
    "    return url\n",
    "\n",
    "get_url_salary(51155454)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "salurl = get_url_salary(51155454) # get url\n",
    "\n",
    "response = requests.get(salurl) # get request\n",
    "r = response.json() # convert the json array text to dictionary\n",
    "\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(r[\"jobInfoArray\"])\n",
    "print(r['jobInfoArray'][0]) #https://stackoverflow.com/questions/51788550/parsing-json-nested-dictionary-using-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r[\"jobInfoArray\"][0]['upperLimit'] # dict name,item #, item name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "salaryrange = str(r[\"jobInfoArray\"][0]['upperLimit']) # dict name,item #, item name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "salaryrange = salaryrange.replace(',', '') # Removes comma so can turn into int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "salaryrange = salaryrange.replace('-', ' ').split(' ') # splits text based on dash or space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "salaryrangelow = int(salaryrange[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "salaryrangehigh = int(salaryrange[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(salaryrangelow)\n",
    "print(salaryrangehigh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Combining it into a function\n",
    "\n",
    "def get_salary(jobid_salary):\n",
    "    \"\"\"Generate a url to get salary info from seek job id and returns data as tuple with low and high\"\"\"\n",
    "    \n",
    "    template = 'https://qdjrmx4vb1.execute-api.ap-southeast-2.amazonaws.com/chickennuggets?jobId={}'\n",
    "    salurl = template.format(jobid_salary)\n",
    "    \n",
    "    \n",
    "    response = requests.get(salurl) # get request\n",
    "    r = response.json() # convert the json array text to dictionary\n",
    "    try:\n",
    "        r[\"jobInfoArray\"][0]['upperLimit'] # dict name,item #, item name \n",
    "        salaryrange = str(r[\"jobInfoArray\"][0]['upperLimit']) # dict name,item #, item name\n",
    "        salaryrange = salaryrange.replace(',', '') # Removes comma so can turn into int\n",
    "        salaryrange = salaryrange.replace('-', ' ').split(' ') # splits text based on dash or space\n",
    "        salaryrangelow = int(salaryrange[0])\n",
    "        salaryrangehigh = int(salaryrange[1])\n",
    "    \n",
    "        return salaryrangelow,salaryrangehigh # return as a tuple - get away from global variables!\n",
    "    \n",
    "    except KeyError: #If it can't find job, will return 0\n",
    "        salaryrangelow = int(0)\n",
    "        salaryrangehigh = int(0)\n",
    "    \n",
    "        return salaryrangelow,salaryrangehigh # return as a tuple - get away from global variables!\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "salaryresult = get_salary(51155454)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(salaryresult[0])\n",
    "print(salaryresult[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together - Version 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from datetime import datetime\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "#Global variables are telling Python that you are using these variables in the global pool. \n",
    "#Using them in local command can cause issues. Think of it as sending variables to the cloud, or local storage. I.e \n",
    "#sharepoint or saving on desktop\n",
    "#https://www.w3schools.com/python/python_variables_global.asp \n",
    "\n",
    "def lookup_id(jobid):\n",
    "    \"\"\"Feed ID for it to look up, will return found or not found\"\"\"\n",
    "    global df  #This is loaded in Main function, as not to load df everytime\n",
    "    lookup = df.loc[df['ID'] == jobid, 'ID'].values\n",
    "    \n",
    "    if lookup.size > 0:\n",
    "        searchResult = 'Found'\n",
    "    else:\n",
    "        searchResult = 'Not found'\n",
    "    \n",
    "    return searchResult\n",
    "\n",
    "def get_salary(jobid_salary): # https://www.whatsthesalary.com/\n",
    "    \"\"\"Generate a url to get salary info from seek job id and returns data as tuple with low and high\"\"\"\n",
    "    \n",
    "    template = 'https://qdjrmx4vb1.execute-api.ap-southeast-2.amazonaws.com/chickennuggets?jobId={}'\n",
    "    salurl = template.format(jobid_salary)\n",
    "    \n",
    "    \n",
    "    response = requests.get(salurl) # get request\n",
    "    r = response.json() # convert the json array text to dictionary\n",
    "    try:\n",
    "        r[\"jobInfoArray\"][0]['upperLimit'] # dict name,item #, item name \n",
    "        salaryrange = str(r[\"jobInfoArray\"][0]['upperLimit']) # dict name,item #, item name\n",
    "        salaryrange = salaryrange.replace(',', '') # Removes comma so can turn into int\n",
    "        salaryrange = salaryrange.replace('-', ' ').split(' ') # splits text based on dash or space\n",
    "        salaryrangelow = int(salaryrange[0])\n",
    "        salaryrangehigh = int(salaryrange[1])\n",
    "    \n",
    "        return salaryrangelow,salaryrangehigh # return as a tuple - get away from global variables!\n",
    "    \n",
    "    except (KeyError,NameError,TypeError): #If it can't find job, will return 0\n",
    "        salaryrangelow = int(0) \n",
    "        salaryrangehigh = int(0)\n",
    "    \n",
    "        return salaryrangelow,salaryrangehigh # return as a tuple - get away from global variables!\n",
    "    \n",
    "def get_url(position, location):\n",
    "    \"\"\"Generate a url from position and location\"\"\"\n",
    "    global search_word # this is for record function\n",
    "    template = 'https://www.seek.co.nz/{}-jobs/in-All-{}'\n",
    "    url = template.format(position, location)\n",
    "    search_word = position\n",
    "    return url\n",
    "\n",
    "\n",
    "def get_record(card):\n",
    "    \"\"\"Extract job data from a single record\"\"\"\n",
    "    global searchResult2 # this is in main function to instruct if CSV exists upon DF load attempt\n",
    "    global search_word # this is from get_url function to add search word to record\n",
    "    global result_to_print # this is ending some text to main to have a user friendly print statement\n",
    "    searchResult = '' # needed only if there is no csv\n",
    "    result_to_print = '' # needed only if there is no csv\n",
    "    \n",
    "    job_id = int(card.get('data-job-id')) # this is what df looks at - as it is unique id - get function as it is high level\n",
    "    \n",
    "\n",
    "    #If there IS a CSV file, run database lookup\n",
    "    if searchResult2 != 'No existing csv file found': \n",
    "        searchResult = lookup_id(job_id)\n",
    "        result_to_print = 'There is a CSV File - Record '+str(searchResult)\n",
    "        \n",
    "    #If there is no match found in df, OR NO CSV file, mine data\n",
    "    if searchResult == 'Not found' or searchResult2 == 'No existing csv file found' : \n",
    "        \n",
    "        job_title = card.find(attrs={\"data-automation\": \"jobTitle\"}).text\n",
    "        job_url = 'https://www.seek.co.nz' + card.find(attrs={\"data-automation\": \"jobTitle\"}).get('href')\n",
    "        \n",
    "        try:\n",
    "            company = card.find(attrs={\"data-automation\": \"jobCompany\"}).text\n",
    "        except AttributeError:\n",
    "            company = ''\n",
    "\n",
    "        location = card.find(attrs={\"data-automation\": \"jobLocation\"}).text\n",
    "\n",
    "        try:\n",
    "            job_salary = card.find(attrs={\"data-automation\": \"jobSalary\"}).text\n",
    "        except AttributeError:\n",
    "            job_salary = ''\n",
    "\n",
    "        job_category = card.find(attrs={\"data-automation\": \"jobClassification\"}).text\n",
    "        job_subcategory = card.find(attrs={\"data-automation\": \"jobSubClassification\"}).text\n",
    "        job_short_description = card.find(attrs={\"data-automation\": \"jobShortDescription\"}).text\n",
    "\n",
    "        try:\n",
    "            job_listing_date = card.find(attrs={\"data-automation\": \"jobListingDate\"}).text\n",
    "        except AttributeError:\n",
    "            job_listing_date = 'Featured'\n",
    "\n",
    "        date_mined = datetime.today().strftime('%Y-%m-%d')\n",
    "        \n",
    "        salaryresult = get_salary(job_id) #Mine salary from https://www.whatsthesalary.com/\n",
    "        salary_low = salaryresult[0]\n",
    "        salary_high = salaryresult[1]\n",
    "        \n",
    "        bullet_points = ''\n",
    "        x = 0\n",
    "        for li in card.select('li'):\n",
    "            if x == 0:\n",
    "                bullet_points = bullet_points + li.text\n",
    "                x = 1\n",
    "            else:\n",
    "                bullet_points = bullet_points + ' - ' + li.text\n",
    "                \n",
    "        #Adds all mined data to list\n",
    "        record = (job_id,search_word,job_title,company,location,job_listing_date,date_mined,job_short_description,\n",
    "                  bullet_points,job_salary,salary_low,salary_high,job_category,job_subcategory,job_url)\n",
    "        \n",
    "        # compiles all the text to let user know information on what happend\n",
    "        result_to_print = result_to_print+' - Added as New Record'\n",
    "       \n",
    "       \n",
    "        return record\n",
    "    \n",
    "    \n",
    "def print_statusline(msg: str): #https://stackoverflow.com/a/43952192/6153315\n",
    "    \"\"\"Prints text inline and deletes properly\"\"\"    \n",
    "    last_msg_length = len(print_statusline.last_msg) if hasattr(print_statusline, 'last_msg') else 0\n",
    "    print(' ' * last_msg_length, end='\\r')\n",
    "    print(msg, end='\\r')\n",
    "#     sys.stdout.flush()  # Some say they needed this, I didn't.\n",
    "    print_statusline.last_msg = msg\n",
    "    \n",
    "\n",
    "    \n",
    "def main(position,location):\n",
    "    \"\"\"Run the main program routine\"\"\"\n",
    "    global searchResult2 # sends this to record function to let it know if there isn't a CSV file\n",
    "    global result_to_print # this is for user friendly print - from record function\n",
    "    global df # this is sending the df to lookup_id function - so df is only loaded once\n",
    "    searchResult2 = '' # else won't be defined if there is a CSV file causing errors\n",
    "    \n",
    "    # Loads CSV and dataframe\n",
    "    try:\n",
    "        df = pd.read_csv('results.csv')  \n",
    " \n",
    "    except FileNotFoundError:\n",
    "        searchResult2 = 'No existing csv file found'\n",
    "        print(searchResult2)\n",
    "     \n",
    "    # Getting the url to mine    \n",
    "    records = []\n",
    "    url = get_url(position, location)\n",
    "    print(url)\n",
    "    \n",
    "    # extract the job data\n",
    "    while True:\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        cards = soup.find_all('article')\n",
    "        x = 1\n",
    "        for card in cards: \n",
    "            time.sleep(2)\n",
    "            record = get_record(card)\n",
    "            if record is not None:   \n",
    "                records.append(record)   \n",
    "            \n",
    "            # this is printing some user friendly, inline text\n",
    "            progressupdate = str(x)+'/'+str(len(cards)) +' - '+result_to_print\n",
    "            result_to_print = ''\n",
    "            print_statusline(progressupdate)\n",
    "\n",
    "            x = x + 1\n",
    "            \n",
    "        # will try to get next seek page, until it can't find the next button    \n",
    "        try:\n",
    "            url = 'https://www.seek.co.nz' + soup.find(attrs={\"data-automation\": \"page-next\"}).get('href')\n",
    "            print(url)\n",
    "        except AttributeError:\n",
    "            print('')\n",
    "            print('no more pages, saving data')\n",
    "            break\n",
    "            \n",
    "            \n",
    "    # save the job data and creates titles/csv file if not already created\n",
    "    if searchResult2 == 'No existing csv file found':\n",
    "        with open('results.csv', 'w', newline='', encoding='utf-8') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(['ID','SearchWord','JobTitle', 'Company', 'Location', 'DateListed', 'DateMined', \n",
    "                             'ShortDesc', 'BulletPoints','AdverSalary','LowSalary','HighSalary','Cat','SubCat','URL'])\n",
    "            writer.writerows(records)\n",
    "            print('saved and done')\n",
    "    \n",
    "    else:\n",
    "        with open('results.csv', 'a', newline='', encoding='utf-8') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerows(records)\n",
    "            print('saved and done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the main program\n",
    "main('Python-Developer','New-Zealand')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iterate through a list of searches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ideally, should be in order of my granulality - as I want it label jobs as accurately as possible. Python will mine tons, while Python developer won't be as many.\n",
    "# So start with specific keywords, then go broader. Exactly how you would search!\n",
    "\n",
    "searchlist = ['Data-Scientist','Automation-Analyst','Continuous-Improvement-Analyst',\n",
    "              'CI-Analyst','Operations-Analyst','Operation-Analyst', 'Python-Developer',\n",
    "              'Commercial-Analyst','Business-Analyst','Data-Analyst','Python']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for search in searchlist:\n",
    "    print(search)\n",
    "    main(search,'New-Zealand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
